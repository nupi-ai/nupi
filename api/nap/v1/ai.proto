syntax = "proto3";

package nupi.nap.v1;

option go_package = "github.com/nupi-ai/nupi/api/nap/v1;napv1";

import "google/protobuf/timestamp.proto";

// ActionType describes the type of action the AI requests.
enum ActionType {
  ACTION_TYPE_UNSPECIFIED = 0;
  ACTION_TYPE_COMMAND = 1;   // Execute a shell command in a session
  ACTION_TYPE_SPEAK = 2;     // Speak a response via TTS
  ACTION_TYPE_CLARIFY = 3;   // Request additional information from user
  ACTION_TYPE_NOOP = 4;      // No action needed
  ACTION_TYPE_TOOL_USE = 5;  // AI requests tool execution
}

// EventType categorizes the type of AI request.
enum EventType {
  EVENT_TYPE_UNSPECIFIED = 0;
  EVENT_TYPE_USER_INTENT = 1;      // Default: interpret user voice/text
  EVENT_TYPE_SESSION_OUTPUT = 2;   // Analyze notable terminal output
  // 3 freed (was HISTORY_SUMMARY)
  EVENT_TYPE_CLARIFICATION = 4;    // Handle user response to clarification
  // 5 freed (was MEMORY_FLUSH)
  EVENT_TYPE_SCHEDULED_TASK = 6;   // Periodic background tasks
  // 7 freed (was SESSION_SLUG)
  EVENT_TYPE_ONBOARDING = 8;                  // First-time user setup
  EVENT_TYPE_JOURNAL_COMPACTION = 9;          // Summarize session journal activity
  EVENT_TYPE_CONVERSATION_COMPACTION = 10;    // Summarize conversation history
}

// ContentOrigin identifies who produced a conversation turn.
enum ContentOrigin {
  CONTENT_ORIGIN_UNSPECIFIED = 0;
  CONTENT_ORIGIN_USER = 1;    // User input (speech/text)
  CONTENT_ORIGIN_AI = 2;      // AI response
  CONTENT_ORIGIN_TOOL = 3;    // Tool/session output
  CONTENT_ORIGIN_SYSTEM = 4;  // System message
}

// SessionInfo provides context about an available terminal session.
message SessionInfo {
  string id = 1;                        // Session identifier
  string command = 2;                   // Main command running (e.g., "claude", "bash")
  repeated string args = 3;             // Command arguments
  string work_dir = 4;                  // Working directory
  string tool = 5;                      // Detected tool type
  string status = 6;                    // Session status (running, detached, stopped)
  google.protobuf.Timestamp start_time = 7;
  map<string, string> metadata = 8;
  string idle_state = 9;                    // Idle state descriptor
  string waiting_for = 10;                  // What the session is waiting for
  google.protobuf.Timestamp idle_since = 11; // When the session became idle
}

// ConversationTurn represents a single turn in conversation history.
message ConversationTurn {
  ContentOrigin origin = 1;
  string text = 2;
  google.protobuf.Timestamp at = 3;
  map<string, string> metadata = 4;
}

// ToolDefinition describes a tool available to the AI for invocation.
message ToolDefinition {
  string name = 1;             // Tool identifier (e.g., "memory_search")
  string description = 2;     // Human-readable description for the AI
  string parameters_json = 3; // JSON Schema describing the tool's parameters
}

// ToolCall represents the AI's request to invoke a specific tool.
message ToolCall {
  string call_id = 1;         // Unique identifier for this invocation
  string tool_name = 2;       // Name of the tool to invoke
  string arguments_json = 3;  // Tool arguments as JSON
}

// ToolResult contains the outcome of a tool invocation.
message ToolResult {
  string call_id = 1;         // Matches the ToolCall.call_id
  string result_json = 2;     // Result data as JSON
  bool is_error = 3;          // True if the tool invocation failed
}

// ToolInteraction pairs a tool call with its result for history tracking.
message ToolInteraction {
  ToolCall call = 1;
  ToolResult result = 2;
}

// ResolveIntentRequest contains context for AI intent resolution.
message ResolveIntentRequest {
  // prompt_id identifies the conversation prompt that triggered this request.
  string prompt_id = 1;

  // session_id is the current session context (may be empty if multiple sessions).
  string session_id = 2;

  // transcript is the user's speech or text input to process.
  string transcript = 3;

  // conversation_history contains recent conversation turns for context.
  repeated ConversationTurn conversation_history = 4;

  // available_sessions lists all sessions the user can interact with.
  repeated SessionInfo available_sessions = 5;

  // config_json contains adapter-specific configuration as JSON.
  string config_json = 6;

  // metadata contains additional context (e.g., detected tool, confidence).
  map<string, string> metadata = 7;

  // event_type categorizes the request (user_intent, session_output, etc.).
  // Adapter can use this to select appropriate processing mode.
  EventType event_type = 8;

  // current_tool is the detected tool/command in the current session.
  // Populated by Nupi's tool detection plugins.
  string current_tool = 9;

  // session_output contains terminal output for EVENT_TYPE_SESSION_OUTPUT requests.
  // This is the notable output that triggered the AI analysis.
  string session_output = 10;

  // clarification_question contains the original question for EVENT_TYPE_CLARIFICATION.
  // This helps the AI understand what clarification was being sought.
  string clarification_question = 11;

  // system_prompt is the pre-built system prompt from Nupi's Prompts Engine.
  // Adapters may use this directly or modify it based on their capabilities.
  string system_prompt = 12;

  // user_prompt is the pre-built user prompt from Nupi's Prompts Engine.
  // Adapters may use this directly or modify it based on their capabilities.
  string user_prompt = 13;

  // available_tools lists tool definitions the AI may invoke during this request.
  // Filtered per event_type by the intent router before sending.
  repeated ToolDefinition available_tools = 14;

  // tool_history contains prior tool call/result pairs from earlier iterations
  // of the same prompt resolution. Empty on the first call; populated on
  // continuation calls so the adapter can reconstruct the full message sequence.
  repeated ToolInteraction tool_history = 15;
}

// IntentAction represents a single action the AI wants to perform.
message IntentAction {
  // type is the action type (command, speak, clarify, noop, tool_use).
  ActionType type = 1;

  // session_ref identifies the target session for command actions.
  string session_ref = 2;

  // command is the shell command to execute (for ACTION_TYPE_COMMAND).
  string command = 3;

  // text is the message to speak or clarification question.
  string text = 4;

  // metadata contains additional action-specific data.
  map<string, string> metadata = 5;
}

// ResolveIntentResponse contains the AI adapter's decision.
message ResolveIntentResponse {
  // prompt_id echoes the request's prompt ID for correlation.
  string prompt_id = 1;

  // actions is the list of actions to perform (usually one, but can be multiple).
  repeated IntentAction actions = 2;

  // reasoning explains the AI's decision (for debugging/logging).
  string reasoning = 3;

  // confidence indicates how confident the AI is in its decision (0.0-1.0).
  float confidence = 4;

  // metadata contains additional response data.
  map<string, string> metadata = 5;

  // error_message is set if the adapter encountered an error.
  string error_message = 6;

  // tool_calls contains tool invocations requested by the AI.
  // Non-empty when an action has type ACTION_TYPE_TOOL_USE.
  repeated ToolCall tool_calls = 7;
}

// Capability describes a single feature or protocol supported by the adapter.
message Capability {
  // name is the feature or protocol identifier (e.g., "streaming", "tool_use").
  string name = 1;

  // version is the capability version string (e.g., "1.0").
  string version = 2;

  // metadata contains additional capability-specific key-value pairs.
  map<string, string> metadata = 3;
}

// GetCapabilitiesRequest is sent to discover adapter capabilities.
message GetCapabilitiesRequest {}

// GetCapabilitiesResponse reports what the adapter supports.
message GetCapabilitiesResponse {
  // adapter_name is the human-readable name of the adapter implementation.
  string adapter_name = 1;

  // adapter_version is the semantic version of the adapter.
  string adapter_version = 2;

  // capabilities lists the features and protocols supported by the adapter.
  repeated Capability capabilities = 3;

  // metadata contains additional adapter-level key-value pairs.
  map<string, string> metadata = 4;
}

// EmbeddingVector holds a single embedding vector.
message EmbeddingVector {
  repeated float values = 1;
}

// EmbeddingRequest asks the adapter to generate embeddings for one or more texts.
message EmbeddingRequest {
  repeated string texts = 1;           // Texts to embed
  string model = 2;                    // Optional model override
  map<string, string> metadata = 3;    // Optional request metadata
}

// EmbeddingResponse returns the generated embeddings.
message EmbeddingResponse {
  repeated EmbeddingVector embeddings = 1; // One vector per input text
  string model_used = 2;                   // Actual model that produced the vectors
  int32 dimensions = 3;                    // Dimensionality of each vector
  string error_message = 4;               // Non-empty on failure
}

// IntentResolutionService exposes the NAP contract for AI adapters.
// AI adapters implement this service to receive user intents and return actions.
//
// Unlike STT (bidirectional streaming) or TTS (server streaming), intent resolution
// is a simple unary RPC - one request, one response. This is because:
// 1. Intent resolution is typically fast (<1s for local models, <5s for cloud)
// 2. There's no streaming data (like audio) to process incrementally
// 3. The response is a discrete decision, not a continuous stream
//
// For streaming scenarios (e.g., token-by-token generation), a separate
// StreamResolveIntent RPC can be added in the future.
service IntentResolutionService {
  // ResolveIntent processes user input and returns intended action(s).
  rpc ResolveIntent(ResolveIntentRequest) returns (ResolveIntentResponse);

  // GetCapabilities returns the adapter's supported features and version info.
  // Adapters that do not implement this RPC will return UNIMPLEMENTED, which
  // callers should treat as "capabilities unknown" and proceed normally.
  rpc GetCapabilities(GetCapabilitiesRequest) returns (GetCapabilitiesResponse);

  // GenerateEmbeddings produces vector embeddings for the given texts.
  // Used by the awareness system for semantic search indexing and queries.
  rpc GenerateEmbeddings(EmbeddingRequest) returns (EmbeddingResponse);
}
