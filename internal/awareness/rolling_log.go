package awareness

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

// Default thresholds for RollingLog.
const (
	DefaultCompactionThreshold = 16000
	DefaultSummaryBudget       = 10000
)

// File format delimiters for the live rolling log file. Uses namespaced XML
// tags (<nupi:...>) to avoid collisions with content generated by AI models.
// Assumption: AI-generated content will not produce these exact namespaced tag
// strings. The nupi-specific namespace makes accidental collision negligible.
const (
	tagSummariesOpen  = "<nupi:rolling-log:summaries>"
	tagSummariesClose = "</nupi:rolling-log:summaries>"
	tagRawOpen        = "<nupi:rolling-log:raw>"
	tagRawClose       = "</nupi:rolling-log:raw>"
)

// RollingLog is a reusable engine for append-only rolling logs with compaction
// and archival support. It maintains summaries and a raw tail in memory,
// persisted to a single live markdown file. Consumers (Journal Service,
// Conversation Log Service) instantiate RollingLog instances for their
// specific use cases.
type RollingLog struct {
	basePath             string
	compactionThreshold  int
	summaryBudget        int
	mu                   sync.RWMutex
	summaries            []string
	rawTail              []string
	summariesByteCount   int
	rawTailByteCount     int
}

// RollingLogOption is a functional option for configuring a RollingLog.
type RollingLogOption func(*RollingLog)

// WithCompactionThreshold sets the character count threshold for raw tail
// compaction. When the raw tail exceeds this size, ShouldCompact() returns true.
func WithCompactionThreshold(n int) RollingLogOption {
	return func(r *RollingLog) {
		if n > 0 {
			r.compactionThreshold = n
		}
	}
}

// WithSummaryBudget sets the character budget for summaries. When summaries
// exceed this size, ShouldArchive() returns true.
func WithSummaryBudget(n int) RollingLogOption {
	return func(r *RollingLog) {
		if n > 0 {
			r.summaryBudget = n
		}
	}
}

// NewRollingLog creates a RollingLog at basePath. If the file exists, state is
// loaded from it. basePath is the full path to the live rolling log file
// (e.g., "journals/{session-id}.md").
//
// Note: compactionThreshold should typically be larger than summaryBudget.
// If summaryBudget exceeds compactionThreshold, archival may never trigger
// because individual compaction summaries are typically smaller than the raw
// text they replace.
func NewRollingLog(basePath string, opts ...RollingLogOption) (*RollingLog, error) {
	if basePath == "" {
		return nil, fmt.Errorf("rolling log: basePath must not be empty")
	}
	if !filepath.IsAbs(basePath) {
		return nil, fmt.Errorf("rolling log: basePath must be absolute: %s", basePath)
	}
	r := &RollingLog{
		basePath:            basePath,
		compactionThreshold: DefaultCompactionThreshold,
		summaryBudget:       DefaultSummaryBudget,
	}
	for _, opt := range opts {
		opt(r)
	}
	if err := r.loadFromFile(); err != nil {
		return nil, fmt.Errorf("rolling log load: %w", err)
	}
	return r, nil
}

// AppendRaw appends text to the in-memory raw tail and persists to file.
// Leading and trailing newlines are trimmed from the input; empty entries after
// trimming are silently ignored. Entries must not contain triple newlines
// ("\n\n\n") as these are used as entry delimiters in the persistence format,
// or file format delimiter tags (<nupi:rolling-log:*>) which would corrupt
// parsing on reload. Double newlines within entries are allowed and preserved
// through round-trips.
// Note: each append triggers a full file rewrite (atomic tmp+rename). This is
// acceptable at expected event frequencies; consider batching if throughput
// becomes a bottleneck.
// If persistence fails, the in-memory state is rolled back to maintain
// consistency with the on-disk file.
func (r *RollingLog) AppendRaw(text string) error {
	text = strings.Trim(text, "\n")
	if text == "" {
		return nil
	}
	if strings.Contains(text, "\n\n\n") {
		return fmt.Errorf("raw entry must not contain triple newlines (would corrupt round-trip parsing)")
	}
	if containsFormatDelimiters(text) {
		return fmt.Errorf("raw entry must not contain file format delimiter tags (would corrupt parsing on reload)")
	}

	r.mu.Lock()
	defer r.mu.Unlock()

	origRawTail := append([]string(nil), r.rawTail...)
	origSize := r.rawTailByteCount

	r.rawTail = append(r.rawTail, text)
	r.rawTailByteCount += len(text)

	if err := r.persistToFile(); err != nil {
		r.rawTail = origRawTail
		r.rawTailByteCount = origSize
		return err
	}
	return nil
}

// AppendSummary appends a summary to the in-memory summaries and persists to file.
// Leading and trailing newlines are trimmed from the input; empty summaries after
// trimming are silently ignored. Summaries must begin with a "### " header
// (e.g., "### [summary] 14:30\n...") for correct round-trip fidelity through file
// persistence — entries without this prefix are rejected. Entries must not contain
// "\n\n### " internally (would split into multiple entries on reload) or file
// format delimiter tags. If persistence fails, the in-memory state is rolled back
// to maintain consistency with the on-disk file.
func (r *RollingLog) AppendSummary(summary string) error {
	summary = strings.Trim(summary, "\n")
	if summary == "" {
		return nil
	}
	if !strings.HasPrefix(summary, "### ") {
		return fmt.Errorf("summary must start with '### ' header for round-trip fidelity")
	}
	if strings.Contains(summary, "\n\n### ") {
		return fmt.Errorf("summary must not contain '\\n\\n### ' (would split into multiple entries on reload)")
	}
	if containsFormatDelimiters(summary) {
		return fmt.Errorf("summary must not contain file format delimiter tags (would corrupt parsing on reload)")
	}

	r.mu.Lock()
	defer r.mu.Unlock()

	origSummaries := append([]string(nil), r.summaries...)
	origSize := r.summariesByteCount

	r.summaries = append(r.summaries, summary)
	r.summariesByteCount += len(summary)

	if err := r.persistToFile(); err != nil {
		r.summaries = origSummaries
		r.summariesByteCount = origSize
		return err
	}
	return nil
}

// RawTailSize returns the total size of the raw tail in bytes.
func (r *RollingLog) RawTailSize() int {
	r.mu.RLock()
	defer r.mu.RUnlock()
	return r.rawTailByteCount
}

// SummariesSize returns the total size of the summaries in bytes.
func (r *RollingLog) SummariesSize() int {
	r.mu.RLock()
	defer r.mu.RUnlock()
	return r.summariesByteCount
}

// ShouldCompact returns true when the raw tail size in bytes exceeds the
// compaction threshold.
func (r *RollingLog) ShouldCompact() bool {
	r.mu.RLock()
	defer r.mu.RUnlock()
	return r.rawTailByteCount > r.compactionThreshold
}

// OlderHalf returns the older half of the raw tail text for AI summarization
// and removes it from the raw tail. The split is by entry count (older 50%).
// If persistence fails, the in-memory state is rolled back to maintain
// consistency with the on-disk file.
func (r *RollingLog) OlderHalf() (string, error) {
	r.mu.Lock()
	defer r.mu.Unlock()

	if len(r.rawTail) == 0 {
		return "", nil
	}

	mid := len(r.rawTail) / 2
	if mid == 0 {
		mid = 1 // at least return something if there's 1 entry
	}

	older := r.rawTail[:mid]
	result := strings.Join(older, "\n\n")

	// Save original state for rollback on persist failure.
	origRawTail := append([]string(nil), r.rawTail...)
	origRawSize := r.rawTailByteCount

	// Keep newer half.
	r.rawTail = append([]string(nil), r.rawTail[mid:]...)
	r.recalcRawSize()

	if err := r.persistToFile(); err != nil {
		r.rawTail = origRawTail
		r.rawTailByteCount = origRawSize
		return "", fmt.Errorf("persist after older half split: %w", err)
	}
	return result, nil
}

// ShouldArchive returns true when the summaries size in bytes exceeds the
// summary budget.
func (r *RollingLog) ShouldArchive() bool {
	r.mu.RLock()
	defer r.mu.RUnlock()
	return r.summariesByteCount > r.summaryBudget
}

// OlderSummaries returns summaries that exceed the budget (from oldest).
// This is read-only — it does not modify live state. Call CommitArchival
// after a successful Archive to remove these summaries from the live file.
//
// IMPORTANT: The archival workflow (OlderSummaries → Archive → CommitArchival)
// must be called from a single goroutine. The lock is released between calls,
// so concurrent AppendSummary or CommitArchival calls can invalidate the
// returned slice count, causing CommitArchival to error or remove wrong entries.
//
// Note: if a single summary exceeds the entire budget, all summaries are
// returned; CommitArchival will then leave the live state empty.
func (r *RollingLog) OlderSummaries() []string {
	r.mu.RLock()
	defer r.mu.RUnlock()

	if len(r.summaries) == 0 {
		return nil
	}

	// Find how many summaries to remove from the front so that the remaining
	// summaries fit within the budget.
	remaining := r.summariesByteCount
	splitIdx := 0
	for splitIdx < len(r.summaries) && remaining > r.summaryBudget {
		remaining -= len(r.summaries[splitIdx])
		splitIdx++
	}

	if splitIdx == 0 {
		return nil
	}

	return append([]string(nil), r.summaries[:splitIdx]...)
}

// CommitArchival removes the first n summaries from live state and persists
// the change to disk. Call this after Archive has successfully written the
// summaries to the archive file. If persistence fails, in-memory state is
// rolled back to avoid divergence from disk.
//
// IMPORTANT: Must be called from the same goroutine as OlderSummaries and
// Archive — see OlderSummaries doc for TOCTOU constraints.
func (r *RollingLog) CommitArchival(n int) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	if n <= 0 {
		return nil
	}
	if n > len(r.summaries) {
		return fmt.Errorf("commit archival: n=%d exceeds summary count=%d", n, len(r.summaries))
	}

	// Save original state for rollback (deep copy for defensive consistency).
	origSummaries := append([]string(nil), r.summaries...)
	origSize := r.summariesByteCount

	r.summaries = append([]string(nil), r.summaries[n:]...)
	r.recalcSummariesSize()

	if err := r.persistToFile(); err != nil {
		r.summaries = origSummaries
		r.summariesByteCount = origSize
		return fmt.Errorf("persist after archival commit: %w", err)
	}
	return nil
}

// Archive appends older summaries to {archivePath}/YYYY-MM-DD.md using the
// archival date (UTC). This method does not acquire the mutex as it operates
// only on its parameters without accessing shared state. Callers should:
//  1. Call OlderSummaries() to identify summaries to archive
//  2. Call Archive() to write them to the archive file
//  3. Call CommitArchival(n) to remove them from live state
//
// Archive uses O_APPEND for race-safe concurrent writes. Multiple RollingLog
// instances may safely archive to the same path concurrently.
func (r *RollingLog) Archive(archivePath string, summaries []string) error {
	if len(summaries) == 0 {
		return nil
	}
	if archivePath == "" {
		return fmt.Errorf("archive: archivePath must not be empty")
	}
	if !filepath.IsAbs(archivePath) {
		return fmt.Errorf("archive: archivePath must be absolute: %s", archivePath)
	}

	if err := os.MkdirAll(archivePath, 0o755); err != nil {
		return fmt.Errorf("create archive dir: %w", err)
	}

	date := time.Now().UTC().Format("2006-01-02")
	filename := filepath.Join(archivePath, date+".md")

	content := "\n\n" + strings.Join(summaries, "\n\n") + "\n"

	f, err := os.OpenFile(filename, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0o600)
	if err != nil {
		return fmt.Errorf("open archive file: %w", err)
	}

	// Always prepend separator for race-safe concurrent appends. On new files
	// this produces a leading blank line, which is harmless in markdown and
	// avoids a TOCTOU race from checking file size before writing.
	if _, err := f.WriteString(content); err != nil {
		f.Close()
		return fmt.Errorf("write archive: %w", err)
	}
	if err := f.Sync(); err != nil {
		f.Close()
		return fmt.Errorf("sync archive: %w", err)
	}
	if err := f.Close(); err != nil {
		return fmt.Errorf("close archive file: %w", err)
	}
	return nil
}

// GetContext returns the summaries (paragraph-aligned) and full raw tail for
// use in AI prompts.
func (r *RollingLog) GetContext() (summaries string, raw string, err error) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	raw = strings.Join(r.rawTail, "\n\n")
	summaries = r.paragraphAlignedSummaries()
	return summaries, raw, nil
}

// WriteLog appends text to {logsPath}/YYYY-MM-DD.md (date in UTC). This is
// append-only and never modifies existing content. Empty or whitespace-only
// text is silently ignored. Like Archive, this method does not access receiver
// state — it operates only on its parameters.
func (r *RollingLog) WriteLog(logsPath string, text string) error {
	if logsPath == "" {
		return fmt.Errorf("write log: logsPath must not be empty")
	}
	if !filepath.IsAbs(logsPath) {
		return fmt.Errorf("write log: logsPath must be absolute: %s", logsPath)
	}
	if strings.TrimSpace(text) == "" {
		return nil
	}
	if err := os.MkdirAll(logsPath, 0o755); err != nil {
		return fmt.Errorf("create logs dir: %w", err)
	}

	date := time.Now().UTC().Format("2006-01-02")
	filename := filepath.Join(logsPath, date+".md")

	f, err := os.OpenFile(filename, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0o600)
	if err != nil {
		return fmt.Errorf("open log file: %w", err)
	}

	if _, err := f.WriteString(text + "\n"); err != nil {
		f.Close()
		return fmt.Errorf("write log: %w", err)
	}
	if err := f.Sync(); err != nil {
		f.Close()
		return fmt.Errorf("sync log: %w", err)
	}
	if err := f.Close(); err != nil {
		return fmt.Errorf("close log file: %w", err)
	}
	return nil
}

// paragraphAlignedSummaries returns summaries with paragraph-aligned truncation.
// It keeps at least summaryBudget bytes from the end, then scans backward
// from the cut point to find a paragraph boundary: first tries "\n\n###"
// (header boundary), then falls back to "\n\n" (empty line boundary).
// Per spec: "skanujemy od końca, cofamy się do granicy paragrafu (### header
// lub pusta linia)".
func (r *RollingLog) paragraphAlignedSummaries() string {
	if len(r.summaries) == 0 {
		return ""
	}

	combined := strings.Join(r.summaries, "\n\n")

	// If total is within budget, return all.
	if len(combined) <= r.summaryBudget {
		return combined
	}

	// Keep at least summaryBudget bytes from the end.
	cutPoint := len(combined) - r.summaryBudget

	// Search backward from cutPoint for a paragraph boundary.
	searchRegion := combined[:cutPoint]

	// Prefer ### header boundary — gives cleaner semantic alignment.
	if idx := strings.LastIndex(searchRegion, "\n\n###"); idx >= 0 {
		return combined[idx+2:]
	}

	// Fall back to empty line boundary (\n\n).
	if idx := strings.LastIndex(searchRegion, "\n\n"); idx >= 0 {
		return combined[idx+2:]
	}

	// No paragraph boundary found before cutPoint — hard cutoff at budget.
	// This avoids returning significantly more than summaryBudget to consumers.
	return combined[cutPoint:]
}

// loadFromFile reads the live file and parses summaries and raw tail sections.
func (r *RollingLog) loadFromFile() error {
	data, err := os.ReadFile(r.basePath)
	if err != nil {
		if os.IsNotExist(err) {
			return nil // No file yet — start empty.
		}
		return fmt.Errorf("read rolling log file: %w", err)
	}

	content := string(data)
	r.summaries, r.rawTail = parseRollingLogFile(content)
	r.recalcSummariesSize()
	r.recalcRawSize()
	return nil
}

// persistToFile writes the current in-memory state to the live file using
// atomic write (tmp + rename).
func (r *RollingLog) persistToFile() error {
	dir := filepath.Dir(r.basePath)
	if err := os.MkdirAll(dir, 0o755); err != nil {
		return fmt.Errorf("create dir for rolling log: %w", err)
	}

	var b strings.Builder
	b.WriteString(tagSummariesOpen)
	b.WriteString("\n\n")
	if len(r.summaries) > 0 {
		b.WriteString(strings.Join(r.summaries, "\n\n"))
		b.WriteString("\n")
	}
	b.WriteString("\n")
	b.WriteString(tagSummariesClose)
	b.WriteString("\n")
	b.WriteString(tagRawOpen)
	b.WriteString("\n\n")
	if len(r.rawTail) > 0 {
		b.WriteString(strings.Join(r.rawTail, "\n\n\n"))
		b.WriteString("\n")
	}
	b.WriteString("\n")
	b.WriteString(tagRawClose)
	b.WriteString("\n")

	tmpPath := r.basePath + ".tmp"
	f, err := os.OpenFile(tmpPath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0o600)
	if err != nil {
		return fmt.Errorf("create temp rolling log: %w", err)
	}
	if _, err := f.WriteString(b.String()); err != nil {
		f.Close()
		os.Remove(tmpPath)
		return fmt.Errorf("write temp rolling log: %w", err)
	}
	if err := f.Sync(); err != nil {
		f.Close()
		os.Remove(tmpPath)
		return fmt.Errorf("sync temp rolling log: %w", err)
	}
	if err := f.Close(); err != nil {
		os.Remove(tmpPath)
		return fmt.Errorf("close temp rolling log: %w", err)
	}
	if err := os.Rename(tmpPath, r.basePath); err != nil {
		os.Remove(tmpPath)
		return fmt.Errorf("rename temp to rolling log: %w", err)
	}
	return nil
}

// parseRollingLogFile parses a rolling log file into summaries and raw tail slices.
// Extracts content between <nupi:rolling-log:summaries> and <nupi:rolling-log:raw>
// XML tag pairs. Malformed files (missing tags) return empty state.
func parseRollingLogFile(content string) (summaries []string, rawTail []string) {
	summariesSection := extractTagContent(content, tagSummariesOpen, tagSummariesClose)
	rawSection := extractTagContent(content, tagRawOpen, tagRawClose)

	summaries = parseSummaries(strings.Trim(summariesSection, "\n"))
	rawTail = parseRawTail(strings.Trim(rawSection, "\n"))
	return summaries, rawTail
}

// extractTagContent returns the content between an opening and closing XML tag.
// Returns empty string if either tag is not found or they are in wrong order.
func extractTagContent(content, openTag, closeTag string) string {
	openIdx := strings.Index(content, openTag)
	if openIdx < 0 {
		return ""
	}
	start := openIdx + len(openTag)

	closeIdx := strings.Index(content[start:], closeTag)
	if closeIdx < 0 {
		return ""
	}
	return content[start : start+closeIdx]
}

// parseSummaries splits the summaries section into individual summary entries.
// Each summary is delimited by "\n\n### " (double newline + header marker).
// The first entry may lack a "### " prefix if the file was manually edited;
// such entries are preserved as-is but may merge with adjacent entries on
// subsequent reloads if they also lack headers.
func parseSummaries(section string) []string {
	if section == "" {
		return nil
	}

	// Split by ### headers preceded by a blank line (matching the join format).
	// Using "\n\n### " avoids false splits on ### sub-headers within a summary body.
	var results []string
	parts := strings.Split(section, "\n\n### ")
	for i, part := range parts {
		trimmed := strings.Trim(part, "\n")
		if trimmed == "" {
			continue
		}
		if i > 0 {
			trimmed = "### " + trimmed
		}
		results = append(results, trimmed)
	}
	return results
}

// parseRawTail splits the raw section into individual entries delimited by
// triple newlines ("\n\n\n"). Double newlines within an entry are preserved.
// Only leading/trailing newlines are trimmed from each entry; internal
// whitespace (including leading spaces on lines) is preserved.
func parseRawTail(section string) []string {
	if section == "" {
		return nil
	}
	parts := strings.Split(section, "\n\n\n")
	var results []string
	for _, part := range parts {
		trimmed := strings.Trim(part, "\n")
		if trimmed != "" {
			results = append(results, trimmed)
		}
	}
	return results
}

// recalcSummariesSize recalculates the total size of summaries in bytes.
// Byte-based sizing is intentional: thresholds are heuristic approximations
// and the minor discrepancy from multi-byte UTF-8 does not affect correctness.
func (r *RollingLog) recalcSummariesSize() {
	total := 0
	for _, s := range r.summaries {
		total += len(s)
	}
	r.summariesByteCount = total
}

// recalcRawSize recalculates the total size of the raw tail in bytes.
func (r *RollingLog) recalcRawSize() {
	total := 0
	for _, s := range r.rawTail {
		total += len(s)
	}
	r.rawTailByteCount = total
}

// containsFormatDelimiters checks if text contains any of the XML tag delimiters
// used in the file persistence format. Embedded delimiters would cause silent data
// loss or truncation on reload.
func containsFormatDelimiters(text string) bool {
	return strings.Contains(text, tagSummariesOpen) ||
		strings.Contains(text, tagSummariesClose) ||
		strings.Contains(text, tagRawOpen) ||
		strings.Contains(text, tagRawClose)
}
